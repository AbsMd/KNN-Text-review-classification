{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5089RdWyujbj",
        "outputId": "29e54fb2-ca7a-4d86-9687-7fae61cb780e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.72)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8noWe4OAOkeR",
        "outputId": "7c799100-c612-4186-a830-db13ca4d07ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3D225mS1OHei"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqtLDhT7VLht",
        "outputId": "1e746613-62fd-4c6f-b94c-2eb3e20db3f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.lm import vocabulary\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jDOA9c0nkx_l"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Handling\n",
        "train_datapath = '/content/drive/MyDrive/code/traindata.csv'\n",
        "train_data = pd.read_csv(train_datapath, header=None)\n",
        "train_data.columns = [\"y\", \"x\"]\n",
        "x_train = train_data[\"x\"]\n",
        "y_train = train_data[\"y\"]\n",
        "test_datapath = '/content/drive/MyDrive/code/testdata.csv'\n",
        "test_data = pd.read_csv(test_datapath, header=None)\n",
        "test_data.columns = [\"x\"]\n",
        "x_test = test_data[\"x\"]"
      ],
      "metadata": {
        "id": "Kg8Ft2Le0tHd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessor function\n",
        "def myPreprocessor(textreview):\n",
        "    fixed_contractions = contractions.fix(textreview)\n",
        "    #Removing HTML tags\n",
        "    textreview_html = BeautifulSoup(fixed_contractions, features=\"html.parser\").get_text() \n",
        "\n",
        "    #Cleaning accents, email IDs, URLs, numbers and punctuation\n",
        "    textreview_proc = re.sub(r'(\\s+@\\s+)|(http[s]?://\\s+)|(\\d)|([^\\w\\s])','', textreview_html)\n",
        "\n",
        "    #Tokenizing the text\n",
        "    tokenizer = ToktokTokenizer()\n",
        "    words= tokenizer.tokenize(textreview_proc)\n",
        "\n",
        "    #Setting and removing stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    textreview_stop = [word for word in words if word not in stop_words and len(word)>3]                  \n",
        "\n",
        "    #Lemmatizing\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_words = ''\n",
        "    lemmatized_words = [str(lemmatizer.lemmatize(word)) + ' ' for word in textreview_stop]\n",
        "    textreview_lemmatized = \"\".join(lemmatized_words)\n",
        "\n",
        "    return textreview_lemmatized.lower()"
      ],
      "metadata": {
        "id": "91HXLdlgwZDn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "z3XOINXsUbXI"
      },
      "outputs": [],
      "source": [
        "class KNearestNeighboursText(object):\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "\n",
        "  #Converting text into features for computing\n",
        "  def getFeatures(self, train_text, test_text):\n",
        "    count_vectorizer = CountVectorizer(preprocessor=myPreprocessor, ngram_range=(1,3), min_df=2, max_df=0.95, \n",
        "                                       max_features=8000)\n",
        "    train_vector = count_vectorizer.fit_transform(train_text)\n",
        "    test_vector = count_vectorizer.transform(test_text)\n",
        "    \n",
        "    return train_vector, test_vector\n",
        "\n",
        "  #Cosine similarity for ranking feature neighbours\n",
        "  def getCosineSimilarity(self, train_vector, test_vector):\n",
        "    similarities = cosine_similarity(test_vector, train_vector)\n",
        "    return similarities\n",
        "  \n",
        "  #k nearest neighbours for the features \n",
        "  def predictScoresNN(self, similarities, score):\n",
        "    self.predicted_scores = []\n",
        "    for similarity in similarities:\n",
        "        #Ranking points by similarity\n",
        "        nearest_neighbours = np.argsort(-similarity)[:self.k] \n",
        "\n",
        "        #Clustering neighbouring points \n",
        "        counter = 0\n",
        "        for neighbor in nearest_neighbours:\n",
        "            if int(score[neighbor]) == 1:\n",
        "                counter += 1\n",
        "                \n",
        "        #Assigning predicted scores\n",
        "        if counter > 0.5*self.k:\n",
        "            self.predicted_scores.append(1)\n",
        "        else:\n",
        "            self.predicted_scores.append(-1)\n",
        "\n",
        "    return self.predicted_scores\n",
        "\n",
        "def main(x_train, y_train, x_test, k):\n",
        "  model = KNearestNeighboursText(k)\n",
        "\n",
        "  train_vec, test_vec = model.getFeatures(x_train, x_test)\n",
        "  sim_matrix = model.getCosineSimilarity(train_vec, test_vec)\n",
        "  del train_vec, test_vec\n",
        "  predicted_scores = model.predictScoresNN(sim_matrix, y_train)\n",
        "\n",
        "  return predicted_scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_testscores = main(x_train, y_train, x_test, k=134)"
      ],
      "metadata": {
        "id": "qgdHtwHD1f1Z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the csv file for predicted test scores\n",
        "np.savetxt(\"predicted_scores.csv\", predicted_testscores, delimiter=\"\\n\", fmt='%d')"
      ],
      "metadata": {
        "id": "hJCVdKqu1d2Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLkL2Ib7ly6V",
        "outputId": "37dacb24-d1e5-40e4-eeee-552dc7f3c792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: \n",
            "Confusion matrix:\n",
            "[[1448  377]\n",
            " [ 299 1476]]\n",
            "Accuracy: 81.22222222222221 \n",
            "\n",
            "Fold 2: \n",
            "Confusion matrix:\n",
            "[[1431  378]\n",
            " [ 329 1462]]\n",
            "Accuracy: 80.36111111111111 \n",
            "\n",
            "Fold 3: \n",
            "Confusion matrix:\n",
            "[[1469  377]\n",
            " [ 301 1453]]\n",
            "Accuracy: 81.16666666666667 \n",
            "\n",
            "Fold 4: \n",
            "Confusion matrix:\n",
            "[[1457  364]\n",
            " [ 313 1466]]\n",
            "Accuracy: 81.19444444444444 \n",
            "\n",
            "Fold 5: \n",
            "Confusion matrix:\n",
            "[[1469  340]\n",
            " [ 336 1455]]\n",
            "Accuracy: 81.22222222222221 \n",
            "\n",
            "[0.8122222222222222, 0.8036111111111112, 0.8116666666666666, 0.8119444444444445, 0.8122222222222222]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8103333333333331"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#K Fold Cross Validation \n",
        "accuracy_list = []\n",
        "k_fold = 5\n",
        "dataset = train_data.to_numpy()\n",
        "l = len(dataset)\n",
        "\n",
        "i=0\n",
        "while (i<k_fold):\n",
        "  kf_split = int((l / k_fold))\n",
        "  m = (i+1) * kf_split\n",
        "\n",
        "  #Data splitting \n",
        "  ts_subset = dataset[l-m:l-m+kf_split]\n",
        "  test_subset = pd.DataFrame(ts_subset)\n",
        "  score_subset_ts = test_subset.iloc[:, 0]\n",
        "  text_subset_ts = test_subset.iloc[:, -1]\n",
        "\n",
        "  tr_subset = np.concatenate((dataset[:l-m], dataset[l-m+kf_split:]), axis=0)\n",
        "  train_subset = pd.DataFrame(tr_subset)\n",
        "  score_subset_tr = train_subset.iloc[:, 0]\n",
        "  text_subset_tr = train_subset.iloc[:, -1]\n",
        "      \n",
        "  actual_scores = score_subset_ts.tolist()\n",
        " \n",
        "  #Calling the KNN model for predicting sentiment scores\n",
        "  predicted_valscores = main(text_subset_tr, score_subset_tr, text_subset_ts, k=134)    \n",
        "\n",
        "  print(\"Fold %d:\" %(i+1), \"\\nConfusion matrix:\")\n",
        "  print(metrics.confusion_matrix(actual_scores, predicted_valscores))\n",
        "  accuracy = metrics.accuracy_score(actual_scores, predicted_valscores)\n",
        "  print(\"Accuracy: %s\" %(100*accuracy), \"\\n\")\n",
        "  accuracy_list.append(accuracy)\n",
        "  i+=1\n",
        "\n",
        "  np.random.shuffle(dataset)\n",
        "  \n",
        "print(accuracy_list)\n",
        "np.mean(accuracy_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TruncatedSVD for dimensionality reduction and spelling correction in preprocessing both resulted in low accuracies, hence omitted"
      ],
      "metadata": {
        "id": "v08rZrDUuv4e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}